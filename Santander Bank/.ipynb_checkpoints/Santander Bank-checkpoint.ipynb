{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.09 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#load the training and test data sets\n",
    "house_train = pd.read_csv(r'C:\\Users\\neera\\Documents\\myGitProjects\\My-Projects\\Santander Bank\\train.csv')\n",
    "\n",
    "house_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_test = pd.read_csv(r'C:\\Users\\neera\\Documents\\myGitProjects\\My-Projects\\Santander Bank\\test.csv')\n",
    "\n",
    "house_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any null values in training dataset\n",
    "\n",
    "house_train.isna().sum().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no null values, which is a good sign for us as we don't need to handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here let us examine the distribution of dependent and few independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "house_train['target'].hist(bins=30)\n",
    "plt.xlabel('target', fontsize=13)\n",
    "plt.ylabel('frequency', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can observe that the training data has almost 90% of the customers who didn't make any transaction, Now this might be difficult for us because of the bias it's gonna impart on our models. We are gonna deal with this later for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.658737</td>\n",
       "      <td>-1.624244</td>\n",
       "      <td>10.707452</td>\n",
       "      <td>6.788214</td>\n",
       "      <td>11.076399</td>\n",
       "      <td>-5.050558</td>\n",
       "      <td>5.415164</td>\n",
       "      <td>16.529143</td>\n",
       "      <td>0.277135</td>\n",
       "      <td>7.569407</td>\n",
       "      <td>...</td>\n",
       "      <td>3.189766</td>\n",
       "      <td>7.458269</td>\n",
       "      <td>1.925944</td>\n",
       "      <td>3.322016</td>\n",
       "      <td>17.996967</td>\n",
       "      <td>-0.133657</td>\n",
       "      <td>2.290899</td>\n",
       "      <td>8.912428</td>\n",
       "      <td>15.869184</td>\n",
       "      <td>-3.246342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.036716</td>\n",
       "      <td>4.040509</td>\n",
       "      <td>2.633888</td>\n",
       "      <td>2.052724</td>\n",
       "      <td>1.616456</td>\n",
       "      <td>7.869293</td>\n",
       "      <td>0.864686</td>\n",
       "      <td>3.424482</td>\n",
       "      <td>3.333375</td>\n",
       "      <td>1.231865</td>\n",
       "      <td>...</td>\n",
       "      <td>4.551239</td>\n",
       "      <td>3.025189</td>\n",
       "      <td>1.479966</td>\n",
       "      <td>3.995599</td>\n",
       "      <td>3.140652</td>\n",
       "      <td>1.429678</td>\n",
       "      <td>5.446346</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>3.008717</td>\n",
       "      <td>10.398589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.188700</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.355200</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>5.484400</td>\n",
       "      <td>-27.767000</td>\n",
       "      <td>2.216400</td>\n",
       "      <td>5.713700</td>\n",
       "      <td>-9.956000</td>\n",
       "      <td>4.243300</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.407000</td>\n",
       "      <td>-3.340900</td>\n",
       "      <td>-11.413100</td>\n",
       "      <td>9.382800</td>\n",
       "      <td>-4.911900</td>\n",
       "      <td>-13.944200</td>\n",
       "      <td>6.169600</td>\n",
       "      <td>6.584000</td>\n",
       "      <td>-39.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.442975</td>\n",
       "      <td>-4.700125</td>\n",
       "      <td>8.735600</td>\n",
       "      <td>5.230500</td>\n",
       "      <td>9.891075</td>\n",
       "      <td>-11.201400</td>\n",
       "      <td>4.772600</td>\n",
       "      <td>13.933900</td>\n",
       "      <td>-2.303900</td>\n",
       "      <td>6.623800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>5.166500</td>\n",
       "      <td>0.882975</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>15.634775</td>\n",
       "      <td>-1.160700</td>\n",
       "      <td>-1.948600</td>\n",
       "      <td>8.260075</td>\n",
       "      <td>13.847275</td>\n",
       "      <td>-11.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.513800</td>\n",
       "      <td>-1.590500</td>\n",
       "      <td>10.560700</td>\n",
       "      <td>6.822350</td>\n",
       "      <td>11.099750</td>\n",
       "      <td>-4.834100</td>\n",
       "      <td>5.391600</td>\n",
       "      <td>16.422700</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>7.632000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162400</td>\n",
       "      <td>7.379000</td>\n",
       "      <td>1.892600</td>\n",
       "      <td>3.428500</td>\n",
       "      <td>17.977600</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>2.403600</td>\n",
       "      <td>8.892800</td>\n",
       "      <td>15.943400</td>\n",
       "      <td>-2.725950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.739600</td>\n",
       "      <td>1.343400</td>\n",
       "      <td>12.495025</td>\n",
       "      <td>8.327600</td>\n",
       "      <td>12.253400</td>\n",
       "      <td>0.942575</td>\n",
       "      <td>6.005800</td>\n",
       "      <td>19.094550</td>\n",
       "      <td>2.930025</td>\n",
       "      <td>8.584825</td>\n",
       "      <td>...</td>\n",
       "      <td>6.336475</td>\n",
       "      <td>9.531100</td>\n",
       "      <td>2.956000</td>\n",
       "      <td>6.174200</td>\n",
       "      <td>20.391725</td>\n",
       "      <td>0.837900</td>\n",
       "      <td>6.519800</td>\n",
       "      <td>9.595900</td>\n",
       "      <td>18.045200</td>\n",
       "      <td>4.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.323400</td>\n",
       "      <td>9.385100</td>\n",
       "      <td>18.714100</td>\n",
       "      <td>13.142000</td>\n",
       "      <td>16.037100</td>\n",
       "      <td>17.253700</td>\n",
       "      <td>8.302500</td>\n",
       "      <td>28.292800</td>\n",
       "      <td>9.665500</td>\n",
       "      <td>11.003600</td>\n",
       "      <td>...</td>\n",
       "      <td>20.359000</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.005000</td>\n",
       "      <td>17.632600</td>\n",
       "      <td>27.947800</td>\n",
       "      <td>4.545400</td>\n",
       "      <td>15.920700</td>\n",
       "      <td>12.275800</td>\n",
       "      <td>26.538400</td>\n",
       "      <td>27.907400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var_0          var_1          var_2          var_3  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       10.658737      -1.624244      10.707452       6.788214   \n",
       "std         3.036716       4.040509       2.633888       2.052724   \n",
       "min         0.188700     -15.043400       2.355200      -0.022400   \n",
       "25%         8.442975      -4.700125       8.735600       5.230500   \n",
       "50%        10.513800      -1.590500      10.560700       6.822350   \n",
       "75%        12.739600       1.343400      12.495025       8.327600   \n",
       "max        22.323400       9.385100      18.714100      13.142000   \n",
       "\n",
       "               var_4          var_5          var_6          var_7  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       11.076399      -5.050558       5.415164      16.529143   \n",
       "std         1.616456       7.869293       0.864686       3.424482   \n",
       "min         5.484400     -27.767000       2.216400       5.713700   \n",
       "25%         9.891075     -11.201400       4.772600      13.933900   \n",
       "50%        11.099750      -4.834100       5.391600      16.422700   \n",
       "75%        12.253400       0.942575       6.005800      19.094550   \n",
       "max        16.037100      17.253700       8.302500      28.292800   \n",
       "\n",
       "               var_8          var_9  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.277135       7.569407  ...       3.189766       7.458269   \n",
       "std         3.333375       1.231865  ...       4.551239       3.025189   \n",
       "min        -9.956000       4.243300  ...     -14.093300      -2.407000   \n",
       "25%        -2.303900       6.623800  ...      -0.095000       5.166500   \n",
       "50%         0.372000       7.632000  ...       3.162400       7.379000   \n",
       "75%         2.930025       8.584825  ...       6.336475       9.531100   \n",
       "max         9.665500      11.003600  ...      20.359000      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.925944       3.322016      17.996967      -0.133657   \n",
       "std         1.479966       3.995599       3.140652       1.429678   \n",
       "min        -3.340900     -11.413100       9.382800      -4.911900   \n",
       "25%         0.882975       0.587600      15.634775      -1.160700   \n",
       "50%         1.892600       3.428500      17.977600      -0.162000   \n",
       "75%         2.956000       6.174200      20.391725       0.837900   \n",
       "max         8.005000      17.632600      27.947800       4.545400   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.290899       8.912428      15.869184      -3.246342  \n",
       "std         5.446346       0.920904       3.008717      10.398589  \n",
       "min       -13.944200       6.169600       6.584000     -39.457800  \n",
       "25%        -1.948600       8.260075      13.847275     -11.124000  \n",
       "50%         2.403600       8.892800      15.943400      -2.725950  \n",
       "75%         6.519800       9.595900      18.045200       4.935400  \n",
       "max        15.920700      12.275800      26.538400      27.907400  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "\n",
    "train_scaled = std_scaler.fit_transform(house_train.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_dropped = house_train.drop(['ID_code','target'], axis=1)\n",
    "scaled_train = pd.DataFrame(train_scaled, columns=target_dropped.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca_scaled = PCA()\n",
    "pca_scaled_ft = pca_scaled.fit_transform(scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_scaled.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we can observe that all the features have similar variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var = np.around(pca_scaled.explained_variance_ratio_, decimals=4)*100\n",
    "\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cum_var = np.cumsum(var)\n",
    "\n",
    "cum_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cum_var)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.title('PCA Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As from the above plot we can observe that PCA doesn't help us in reducing any dimensions as the variance explained by each feature is almost is similar. So now we'll try to work with filter methods to see if we can reduce any dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the PCA explained variances we can observe that all the features have similar variances and without any zero variance, but as the variances are similar there might be chance for multi collinearity or duplicity. So we'll check for them below and see if we can drop unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = house_train.drop('ID_code', axis=1)\n",
    "\n",
    "house_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_tsld = VarianceThreshold(threshold=0)\n",
    "\n",
    "var_ft = var_tsld.fit_transform(house_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_tsld.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any of the above variances are equal to zero\n",
    "print(any(i == 0 for i in var_tsld.get_support()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "train_mm_scaled = mm_scaler.fit_transform(house_train.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mm_scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mm_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaled_train = pd.DataFrame(train_mm_scaled, columns=target_dropped.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaled_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_var = var_tsld.fit_transform(mm_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_tsld.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tsld.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can understand that there are no features with '0' variance, which we already observed from PCA's variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see if we can remove any quasi constant features that might provide little variance. We'll use standard rule of thumb 99% threshold value to see if we have any similar features for the output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "quas_tsld = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "quas_ft = quas_tsld.fit_transform(house_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_quas = quas_tsld.fit_transform(mm_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quas_tsld.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quas_tsld.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all(i >0.01 for i in quas_tsld.get_support()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no features to remove considering quasi constant. So now we'll try to see if we have duplicate features, which I think there will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trns = house_train.T\n",
    "\n",
    "train_trns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trns_dup = train_trns.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_dup.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there are no correlated features, which is unexpected as I assumed as variances are almost similar there would be atleast duplicate features, but we'll just proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we'll try to see if there's multicollinearity among the features with respect to dependent variable and see if we remove any features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_corr = house_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_corr['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_corr_trgt = x_corr['target'].sort_values(ascending=False).drop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_corr_trgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.barh(sorted_corr_trgt.index, sorted_corr_trgt.values)\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.ylabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=x_corr['target'].drop('target'))\n",
    "plt.xlabel('Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll filter out the features having correlation values with greater than absolute value of 0.02 with target. These features have high influence on predicting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_features = x_corr[abs(x_corr['target']) > 0.02].index.drop('target')\n",
    "\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_corr.loc[selected_features,selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(x_corr.loc[selected_features,selected_features], vmin = -1.0, vmax = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mutual_x_train = mutual_info_classif(house_train[selected_features], house_train['target'])\n",
    "\n",
    "mutual_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.Series(mutual_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mutual_info.index = selected_features\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(18,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of selecting top few features, I'm gonna select features with mutual information of atleast 0.001 because if we select only like top 10 or 15 features, we miss a lot of collective information from remaining features. If this approach reults in greater variance when the predictions are made, we'll come back to this try selecting top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(mutual_info[mutual_info>1.e-03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are 60 features with mutual information value greater than 0.01, we will select these features and try to run our models. we cut down from 200 features to 60 features, I think that's pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = mutual_info[mutual_info>1.e-03].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train, x_test, y_train, y_test = train_test_split(house_train[selected_features], house_train['target'], train_size=0.7, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[selected_features]\n",
    "#x_test = x_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we are ready with our features, there's one more thing we need to make sure before applying any models, which is balancing the class labels. We know already that the target variable has highly imbalanced. So we'll try to take care of that if we don't want our models to be biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(house_train['target'])/len(house_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y==1])/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(penalty='none', solver = 'sag', max_iter = 300)\n",
    "\n",
    "def train_model(x_train, x_test, y_train, y_test, fold_num):\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    pred = lr_model.predict(x_test)\n",
    "    accr = accuracy_score(y_test, pred)\n",
    "    print(f\"Accuracy Score for this fold is : {accr}\")\n",
    "    \n",
    "    conf_mat = confusion_matrix(y_test, pred)\n",
    "    print(f\"Confusion matrix for fold {fold_num} : '\\'n {conf_mat}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_train[selected_features]\n",
    "y = house_train['target']\n",
    "\n",
    "strat_kfold = StratifiedKFold(n_splits=2)\n",
    "\n",
    "fold_num = 1\n",
    "for train_index, test_index in strat_kfold.split(X, y):\n",
    "    print('fold', str(fold_num))\n",
    "    \n",
    "    x_train = X.loc[train_index,:]\n",
    "    x_test = X.loc[test_index,:]\n",
    "    y_train = y.loc[train_index]\n",
    "    y_test = y.loc[test_index]\n",
    "    \n",
    "    print(f\"class ratio in y_train = {len(y_train[y_train==1])/len(y_train)}\")\n",
    "    print(f\"class ratio in y_test = {len(y_test[y_test==1])/len(y_test)}\")\n",
    "    \n",
    "    #Now we'll train the model by passing the training and test data as paramenters\n",
    "    train_model(x_train, x_test, y_train, y_test, fold_num)\n",
    "\n",
    "    fold_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier(n_estimators=500, n_jobs=-1, max_depth=6, min_samples_split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# fit_rf = rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(sns.catplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.catplot(data=house_train, y='var_0', x='target', kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(data=house_train, x='target', y='var_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
